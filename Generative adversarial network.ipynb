{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4267e63",
   "metadata": {},
   "source": [
    "# Generative adversarial network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6535e738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b51bee7",
   "metadata": {},
   "source": [
    "## 模型定义"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd744906",
   "metadata": {},
   "source": [
    "### 判别器\n",
    "利用线性层对输入进行线性变换，激活函数使用 `LeakyReLU`  \n",
    "辨别器输入：形状为 \\[batch_size, infeatures\\] 的向量  \n",
    "辨别器输出：得分"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7642b31",
   "metadata": {},
   "source": [
    "$LeakyRule(x) = \\begin {cases} x, if x \\ge 0 \\\\ negative\\_slope \\times x, otherwise \\end{cases}$  \n",
    "shape:  \\[batch_size, in_features\\]  $\\Rightarrow$  \\[batch_size, hidden_size\\]  $\\Rightarrow$  \\[batch_size, hidden_size\\]  $\\Rightarrow$  \\[batch_size, 1\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12913914",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_features, hidden_size):\n",
    "        super().__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(in_features, hidden_size),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_size, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.disc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d8f8c1",
   "metadata": {},
   "source": [
    "### 生成器\n",
    "利用线性层对输入进行线性变换，激活函数前两个线性层使用 `ReLU`，最后一层使用 `Tanh`    \n",
    "生成器输入：形状为 \\[batch_size, z_dim\\] 的随机向量  \n",
    "输出：形状为 \\[batch_size, img_dim\\] 的向量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299fc0b8",
   "metadata": {},
   "source": [
    "$Tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}$  \n",
    "shape: \\[batch_size, z_dim\\]  $\\Rightarrow$  \\[batch_size, hidden_size\\]  $\\Rightarrow$  \\[batch_size, hidden_size\\]  $\\Rightarrow$  \\[batch_size, img_dim\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b88787",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_size, img_dim):\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(z_dim, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, img_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.gen(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de58b3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "in_features = 784\n",
    "hidden_size = 256\n",
    "lr = 2e-4\n",
    "z_dim = 64\n",
    "img_dim = 28*28*1\n",
    "batch_size = 256\n",
    "num_epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6de712",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = Discriminator(in_features, hidden_size).to(device)\n",
    "gen = Generator(z_dim, hidden_size, img_dim).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b82e6e",
   "metadata": {},
   "source": [
    "## 数据集准备\n",
    "本次实验使用 `MNIST` 数据集  \n",
    "transform 用于将图片转换为 tensor (形状：\\[C, H, W\\] (1,28,28)), 并对 tensor 进行归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b0cb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise = torch.randn((100, z_dim)).to(device)\n",
    "transform = transform.Compose(\n",
    "    [transform.ToTensor(), transform.Normalize(mean=(0.5,), std=(0.5,))]\n",
    ")\n",
    "\n",
    "dataset = datasets.MNIST(root='dataset/mnist/', transform=transform, download=False)\n",
    "loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb34c2c",
   "metadata": {},
   "source": [
    "## Optimizer 和Criterion\n",
    "**BCELoss**  \n",
    "$-\\frac{1}{N}\\sum^N_{i=1}y_ilog(x_i)+(1-y_i)log(1-x_i)$  \n",
    "使用 `BCELoss` 的目的是让模型的分布接近于未知的真实分布，模型的优化目标是最大化训练数据的概率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470ddd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_disc = optim.Adam(disc.parameters(), lr=lr)\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da52b07",
   "metadata": {},
   "source": [
    "由于归一化后的图片张量的像素值在 \\[-1, 1\\] 之间，为了便于图片的可视乎，定义 `denorm()` 函数来实现反归一化。  \n",
    "`save_fake_img()` 用于保存图片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed776d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Image\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "sample_dir = 'samples'\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "    \n",
    "def denorm(x):\n",
    "    x = (x + 1) / 2\n",
    "    return x.clamp(0, 1)\n",
    "\n",
    "def save_fake_img(index):\n",
    "    fake_images = gen(fixed_noise)\n",
    "    fake_images = fake_images.reshape(-1, 1, 28, 28)\n",
    "    fname = 'fake_images-{0:0=4d}.png'.format(index)\n",
    "    print('Saving', fname)\n",
    "    save_image(denorm(fake_images), os.path.join(sample_dir, fname), nrow=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb308872",
   "metadata": {},
   "source": [
    "## 模型训练\n",
    "### 判别器训练\n",
    "1. 我们希望判别器对于真实图片输出 1，对生成的图片输出 0  \n",
    "2. 首先向判别器输入一批真实图片，并计算 loss，该步的标签设置为 1\n",
    "3. 接着，生成一批假图片输出到判别器， 并计算 loss， 该步的标签设置为 0\n",
    "4. 最后，求两个 loss 的均值，利用梯度下降调整判别器的参数  \n",
    "\n",
    "### 生成器训练\n",
    "1. 我们使用生成器生成一批假图片，并传入判别器进行打分\n",
    "2. 该步的标签设置为 1， 根据判别器的输出计算 loss\n",
    "3. 根据上步的 loss 进行梯度下降调整生成器的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d53f79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "d_losses , g_losses = [], []\n",
    "for epoch in range(num_epochs):\n",
    "    since = time.time()\n",
    "    for idx, (real, _) in  enumerate(loader):\n",
    "        real = real.reshape(-1, 784).to(device)\n",
    "        train_batch_size  = real.shape[0]\n",
    "        \n",
    "        noise = torch.randn((train_batch_size, z_dim)).to(device)\n",
    "        fake = gen(noise)\n",
    "        disc_real = disc(real).reshape(-1)\n",
    "        lossD_real = criterion(disc_real,torch.ones_like(disc_real))\n",
    "        disc_fake= disc(fake).reshape(-1)\n",
    "        lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "        lossD = (lossD_real + lossD_fake) / 2\n",
    "        opt_disc.zero_grad()\n",
    "        lossD.backward(retain_graph=True)\n",
    "        opt_disc.step()\n",
    "        \n",
    "        output = disc(fake).reshape(-1)\n",
    "        lossG = criterion(output, torch.ones_like(output))\n",
    "        opt_gen.zero_grad()\n",
    "        lossG.backward()\n",
    "        opt_gen.step()\n",
    "        \n",
    "        d_losses.append(lossD.item())\n",
    "        g_losses.append(lossG.item())\n",
    "        \n",
    "        if (idx+1) % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch+1}/{num_epochs}], Step [{idx+1}/{len(loader)}], Loss D: {lossD:.4f}, loss G: {lossG:.4f}, time: {time.time()-since:.4f}\"\n",
    "            )\n",
    "        \n",
    "    save_fake_img(epoch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd595e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(disc.state_dict(), 'D.ckpt')\n",
    "torch.save(gen.state_dict(), 'G.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df44535d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(d_losses, '-')\n",
    "plt.plot(g_losses, '-')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['Discriminator', 'Generator'])\n",
    "plt.title('BCELoss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f127af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c4bb4f",
   "metadata": {},
   "source": [
    "## 加载模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c220caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disc.load_state_dict(torch.load('D.ckpt'))\n",
    "# disc.eval()\n",
    "gen.load_state_dict(torch.load('G.ckpt'))\n",
    "gen.eval()\n",
    "\n",
    "# print(disc)\n",
    "# print()\n",
    "print(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24959ffe",
   "metadata": {},
   "source": [
    "## 测试生成器效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc499f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "randn_noise = torch.randn((batch_size, z_dim)).to(device)\n",
    "fake = gen(randn_noise).reshape(-1, 1, 28, 28)\n",
    "save_image(denorm(fake),os.path.join(sample_dir, 'test_result.png'), nrow = 20)\n",
    "\n",
    "Image(os.path.join(sample_dir, 'test_result.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2d5418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3ab488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from IPython.display import FileLink\n",
    "\n",
    "vid_fname = 'gan_traning.avi'\n",
    "files = [os.path.join(sample_dir, f) for f in os.listdir(sample_dir) if 'fake_images' in  f]\n",
    "files.sort()\n",
    "\n",
    "out = cv2.VideoWriter(vid_fname, cv2.VideoWriter_fourcc(*'MJPG'), 8, (302, 302))\n",
    "[out.write(cv2.imread(fname)) for fname in  files]\n",
    "out.release()\n",
    "FileLink('gan_traning.avi')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
